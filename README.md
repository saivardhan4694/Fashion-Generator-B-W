# Fashion-Generator-B-W
This repository contains GAN network to generate black and white fashion images

# Introduction

The FashionGAN project is a creative exploration into generative adversarial networks (GANs) specifically tailored for generating fashion images. GANs, a powerful subset of machine learning models, consist of two neural networks—the generator and the discriminator—that are trained together to produce realistic images from random noise. The generator learns to create images that mimic real fashion designs, while the discriminator tries to distinguish between the generator's fake images and actual fashion images. Over time, this adversarial process results in the generator producing increasingly convincing fashion images that are almost indistinguishable from real-life examples.

This project utilizes a comprehensive dataset of fashion images to train the GAN model. By feeding the generator network with random noise vectors, it learns to generate a diverse range of fashion items, from casual wear to formal attire, capturing various styles, patterns, and colors. This enables us to explore and visualize new fashion designs that do not exist in the current market, providing insights into potential future trends. The trained generator model can be used to inspire designers or even to automate the initial design process, pushing the boundaries of creativity in fashion.

Through this README, you will find a detailed guide on how to replicate the results, the underlying theory behind GANs, and instructions on how to use the trained model for your own fashion image generation needs.

# Dataset Overview

The dataset used for this project is the FashionMNIST dataset from TensorFlow. FashionMNIST is a popular dataset consisting of grayscale images of fashion items. It contains 60,000 training images and 10,000 testing images, each of size 28x28 pixels, depicting various clothing items such as shirts, trousers, shoes, and bags. The images are labeled into one of ten classes, representing different types of fashion items. This dataset is strictly in black and white, providing a challenging task for generating realistic images through a Generative Adversarial Network (GAN). The simplicity of the images, coupled with the nuanced differences between classes, makes FashionMNIST a compelling choice for exploring generative models in computer vision.

To prepare the dataset for training, standerd tensorflow dataset pipeline was set. First, the images were loaded and normalized using a custom function to scale the pixel values to a range between 0 and 1, which is essential for stable GAN training. The dataset was then cached to improve data retrieval speed, shuffled to ensure randomness in the training process, and batched into groups of 128 images to efficiently manage memory usage and optimize training performance. Finally, prefetching was used to overlap data preprocessing with model execution, reducing the likelihood of bottlenecks and improving the overall efficiency of the training process.

# Model Architecture

The Generator is designed to create realistic images from random noise, essentially learning to mimic the distribution of the training data. The architecture of the Generator is primarily composed of several layers of Transposed Convolutions (also known as Deconvolutions or Up-sampling layers).

## Generator 

The Generator is designed to create realistic images from random noise, essentially learning to mimic the distribution of the training data. The architecture of the Generator is primarily composed of several layers of Transposed Convolutions (also known as Deconvolutions or Up-sampling layers).

Input Layer: The input to the Generator is a random noise vector, typically sampled from a Gaussian distribution. For this project, a 128-dimensional vector is used as input.

Dense Layer: The noise vector is first passed through a dense layer with a significant number of units (e.g., 7x7x256) and reshaped to form a small, low-resolution image-like representation.

Transposed Convolutional Layers: Following the dense layer, a series of transposed convolutional layers are applied. These layers upsample the input, progressively increasing the spatial dimensions of the data (e.g., from 7x7 to 14x14, and finally to 28x28). Each layer is typically followed by a Batch Normalization layer to stabilize training and a ReLU activation function to introduce non-linearity.

Output Layer: The final layer of the Generator uses a transposed convolutional layer with a sigmoid activation function to output an image of size 28x28x1 for grayscale images (or 28x28x3 for color images). The sigmoid activation ensures that the pixel values are in the range [0, 1], matching the normalized data.

## Discriminator

The Discriminator’s role is to distinguish between real images from the training set and fake images generated by the Generator. It is essentially a binary classifier that outputs the probability of an image being real.

Input Layer: The Discriminator takes an image of size 28x28x1 (or 28x28x3 for color images) as input.

Convolutional Layers: The input image is passed through several convolutional layers that progressively reduce the spatial dimensions while increasing the depth of the feature maps. These layers use Leaky ReLU activations, which help to avoid the "dying ReLU" problem and allow the gradient to flow through the network more effectively.

Flatten and Dense Layers: The feature maps are flattened into a one-dimensional vector, which is then passed through one or more dense layers. These dense layers further process the features extracted from the input images.

Output Layer: The final output layer is a dense layer with a single unit and a sigmoid activation function, providing a probability score indicating whether the input image is real (close to 1) or fake (close to 0).

# Training of FashionGAN

The training process of a GAN involves a unique adversarial approach where both the Generator and the Discriminator are trained in tandem but with opposing objectives. The Discriminator aims to distinguish between real and fake images, while the Generator seeks to create images that are increasingly convincing to the Discriminator. So, for this we needed to setup a coustom training loop using tensorflow. The fallowing is the description of the coustom training loop that we have defined for this,

Discriminator Training: The Discriminator is trained by first feeding it a batch of real images from the dataset and a batch of fake images generated by the Generator. The outputs for both real and fake images are concatenated and compared against labels indicating whether they are real or fake. To introduce a level of robustness, noise is added to the labels for real and fake images to avoid the model becoming too confident in its predictions. The loss is then computed using binary cross-entropy, which measures the Discriminator's ability to correctly classify real and fake images. The gradients are calculated with respect to the Discriminator's weights, and the optimizer updates the model parameters to minimize the loss, effectively training the Discriminator to become more discerning.

Generator Training: After updating the Discriminator, the focus shifts to the Generator. The Generator is tasked with creating images that are as convincing as possible to the Discriminator. To achieve this, a batch of new images is generated from random noise. These images are then passed through the Discriminator to obtain predicted labels. The Generator's loss is calculated based on how well these images manage to fool the Discriminator into classifying them as real. By minimizing this loss, the Generator is trained to improve its output quality, aiming to produce images that are increasingly indistinguishable from genuine samples.

Optimizers and Loss Functions: The training utilizes the Adam optimizer for both the Generator and Discriminator, with different learning rates to balance the training dynamics. The Generator employs a learning rate of 0.0001, while the Discriminator uses a slightly lower rate of 0.00001. This differential learning rate helps in stabilizing the adversarial process, ensuring that neither model dominates the training process. Both models use binary cross-entropy as their loss function, which is suitable for binary classification tasks. This approach ensures that the Discriminator and Generator effectively learn from their adversarial interactions, driving improvements in both generating and evaluating images over the course of the training.

# Results

The results of the FashionGAN project highlight the effectiveness of the model in generating high-quality fashion images. The training process, which utilized the Fashion-MNIST dataset, demonstrated substantial progress in the ability of the Generator to produce visually appealing images that closely resemble the real fashion items.

Visual Evaluation: One of the primary ways to assess the performance of the GAN is through visual inspection of the generated images. During the training, the Generator progressively produced images with increasing fidelity, starting from random noise and evolving into realistic fashion images. These images were compared to samples from the Fashion-MNIST dataset, showcasing the Generator's capability to capture intricate details and patterns typical of fashion apparel. The final outputs reflect a significant improvement in quality, with generated images showing clear features and textures of clothing items. For instance, the model successfully created diverse apparel types, including shirts, trousers, and shoes, each with distinct styles and attributes.

Training Dynamics: Throughout the training process, the loss curves for both the Generator and Discriminator were monitored. The Discriminator's loss decreased over time, indicating that it was becoming better at distinguishing between real and fake images. Concurrently, the Generator's loss also showed a downward trend, signifying that the Generator was improving its ability to produce convincing images. This dynamic interplay between the Generator and Discriminator is a critical aspect of GAN training, and the observed trends suggest that the models were effectively learning and adapting to each other's improvements.

At the end of the training, the FashionGAN was capable of generating fashion images that were not only visually appealing but also demonstrated a high degree of realism. The generated images included various fashion items with detailed textures and patterns, closely mirroring the original dataset. The successful generation of these images underscores the effectiveness of the GAN architecture and training approach used in this project. The results illustrate the potential of GANs in creative applications such as fashion design and image synthesis, providing a solid foundation for further exploration and development in the field of generative adversarial networks.

# Usage

To use the FashionGAN model:

Clone the repository from GitHub.
Install the required dependencies listed in the requirements.txt.
Load the trained generator model using TensorFlow/Keras.
Generate new fashion images by providing random noise vectors as input to the generator.

The python code to use this fashiongan model is provided in the Example Usage file in this repository. you can just open it in colab and use it.






